[DIRECTORY]
project_pt = ../../Are-you-happy-FileSystem/
data_pt = %(project_pt)s/data/
devel_pt = %(data_pt)s/devel/
source_pt = %(data_pt)s/source/
origin_pt = %(data_pt)s/origin/
feature_pt = %(data_pt)s/feature/
index_pt = %(data_pt)s/index/
label_pt = %(data_pt)s/label/
feature_analysis_pt = %(data_pt)s/feature_analysis/
origin_spanish_pt = %(data_pt)s/origin_spanish/
csv_spanish_pt = %(data_pt)s/csv_spanish/
csv_spanish_cleaning_pt = %(data_pt)s/csv_spanish_cleaning/
csv_spanish_cleaning_pto = %(data_pt)s/csv_spanish_cleaningO/
out_pt = %(data_pt)s/out/%(out_tag)s/
pred_pt = %(out_pt)s/pred/
index_out_pt = %(out_pt)s/index/
model_pt = %(out_pt)s/model/
fault_pt = %(out_pt)s/fault_pt/
conf_pt = %(out_pt)s/conf/
score_pt = %(out_pt)s/score/

[FILE_NAME]
cikm_english_train_20180516_txt = cikm_english_train_20180516.txt
cikm_spanish_train_20180516_txt = cikm_spanish_train_20180516.txt
cikm_unlabel_spanish_train_20180516_txt = cikm_unlabel_spanish_train_20180516.txt
cikm_test_a_20180516_txt = cikm_test_a_20180516.txt
cikm_english_train_20180516_csv = cikm_english_train_20180516.csv
cikm_spanish_train_20180516_csv = cikm_spanish_train_20180516.csv
cikm_unlabel_spanish_train_20180516_csv = cikm_unlabel_spanish_train_20180516.csv
cikm_test_a_20180516_csv = cikm_test_a_20180516.csv
cikm_english_and_spanish_train_20180516_csv = cikm_english_and_spanish_train_20180516.csv
cikm_english_and_spanish_train_20180516_noid_csv = cikm_english_and_spanish_train_20180516_noid.csv
powerful_word_name = words_power
preprocessing_train_merge_csv = preprocessing_train_merge.csv
preprocessing_test_csv = preprocessing_test.csv
words_txt = words.txt
wiki_es_vec = wiki.es.vec

[SINGLE_EXEC]
se_num = 100
se_train_rate = 0.9
se_cv_rate = 0.09
se_test_rate = 0.01
se_seed = 10
se_tag = 

[CROSS_VALIDATION]
cv_num = 8
cv_tag = 


[MODEL]
model_name = GradientBoost
train_pos_rate = 0.5
valid_pos_rate = 0.5
test_pos_rate = 0.5
offline_rawset_name = train
online_rawset_name = test
lock_name = lock_name
lock_time = 1
lock_pt = C:/Users/jieyang/Desktop/GIT_code/kaggle-quora-question-pairs/
evaluator_name = entropy_loss


[XGB_PARAMS]
booster = gbtree
objective = binary:logistic
eval_metric = logloss
eta = 0.05
max_depth = 6
subsample = 0.7
colsample_bytree = 1
min_child_weight = 50
silent = 1
num_round = 1000
early_stop = 10000
nthread = 6
scale_pos_weight = 0.25
verbose_eval = 50
gamma = 1
lambda = 3
alpha = 2


[LOGISTIC_REGRESSION_PARAMS]
penalty = l2
dual = False
tol = 1e-4
C = 1.
verbose = 0
max_iter = 100
solver = liblinear
n_jobs = 1
multi_class = ovr

[RANDOMFOREST]
n_estimators = 1000
max_features = 10
max_depth = 5
min_samples_split = 50
n_jobs = 6
random_state =0
loss = deviance
verbose = 0

[GBDT]
n_estimators = 400
loss = deviance
max_depth = 5
verbose = 1

[FEATURE]
begin_index = 0
end_index = 21400
will_save = False
offline_rawset_name = preprocessing_train_merge.csv
online_rawset_name = preprocessing_test.csv

feature_selected =
    WordMatchShare
    TFIDFWordMatchShare
    Length
    LengthDiff
    LengthDiffRate
    DulNum
    NgramJaccardCoef
    NgramDiceDistance
    PowerfulWordOneSideRate
    PowerfulWordDoubleSideRate
    NgramOverlapDistance
    NgramDistance_edit_dist
    Not
    TFIDFSpanish
    TFIDF
    PhraseToSentenceDistance_edit_dist
    SVDDecomposition
    NMFDecomposition
    LDADecomposition
    fuzz_QRatio
    fuzz_WRatio
    fuzz_partial_ratio
    fuzz_partial_token_set_ratio
    fuzz_partial_token_sort_ratio
    fuzz_token_set_ratio
    fuzz_token_sort_ratio
    long_common_sequence
    long_common_prefix
    long_common_suffix
    long_common_substring
    levenshtein_distance
    lcs_diff
    RepresenWordToVectorSentenceDistance
    RepresenOneHotSentenceDistance
    RepresenOneHotIdfSentenceDistance
    cnn3_result
    LG
    XGB
    RandomForest

feature_selected_analysis = 
    WordMatchShare
    TFIDFWordMatchShare
    Length
    LengthDiff
    LengthDiffRate
    DulNum
    NgramJaccardCoef
    NgramDiceDistance
    PowerfulWordOneSideRate
    PowerfulWordDoubleSideRate
    NgramOverlapDistance
    NgramDistance_edit_dist
    Not
    TFIDFSpanish
    TFIDF
    PhraseToSentenceDistance_edit_dist
    SVDDecomposition
    NMFDecomposition
    LDADecomposition
    fuzz_QRatio
    fuzz_WRatio
    fuzz_partial_ratio
    fuzz_partial_token_set_ratio
    fuzz_partial_token_sort_ratio
    fuzz_token_set_ratio
    fuzz_token_sort_ratio
    long_common_sequence
    long_common_prefix
    long_common_suffix
    long_common_substring
    levenshtein_distance
    lcs_diff
    RepresenWordToVectorSentenceDistance
    RepresenOneHotSentenceDistance
    RepresenOneHotIdfSentenceDistance
    cnn3_result
    LG
    XGB
    RandomForest


feature_selected_num_analysis =
        WordMatchShare-1-
        TFIDFWordMatchShare-1-
        Length-4-
        LengthDiff-1-
        LengthDiffRate-1-
        DulNum-4-
        NgramJaccardCoef-3-
        NgramDiceDistance-3-
        PowerfulWordOneSideRate-1-
        PowerfulWordDoubleSideRate-1-
        NgramOverlapDistance-6-
        NgramDistance_edit_dist-20-
        Not-5-
        TFIDFSpanish-4-
        TFIDF-6-
        PhraseToSentenceDistance_edit_dist-1-
        SVDDecomposition-1-
        NMFDecomposition-1-
        LDADecomposition-1-
        fuzz_QRatio-1-
        fuzz_WRatio-1-
        fuzz_partial_ratio-1-
        fuzz_partial_token_set_ratio-1-
        fuzz_partial_token_sort_ratio-1-
        fuzz_token_set_ratio-1-
        fuzz_token_sort_ratio-1-
        long_common_sequence-1-
        long_common_prefix-1-
        long_common_suffix-1-
        long_common_substring-1-
        levenshtein_distance-1-
        lcs_diff-1-
        RepresenWordToVectorSentenceDistance-14-
        RepresenOneHotSentenceDistance-1-
        RepresenOneHotIdfSentenceDistance-1-
        cnn3_result-1-
        LG-1-
        XGB-1-
        RandomForest-1-



        
